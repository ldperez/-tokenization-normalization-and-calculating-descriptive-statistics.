{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "import string\n",
    "import matplotlib \n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"/Users/Luis Perez/Documents/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "06522af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Fill in the correct values here. \n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = len(set(tokens)) / len(tokens)\n",
    "    num_characters = sum(len(token)for token in tokens)\n",
    "    #x=sum([len(songs) for songs in cleaned_lyrics['cher'].values()])\n",
    "\n",
    "    \n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: Assertion are useful for both documentation and debugging code. They are most commonly used in testing and user validation. What I understand you want to use them in your code when you want easy to undestand code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "266d39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lyrics data\n",
    "#data_location = \"/Users/Luis Perez/Documents/lyrics\"\n",
    "\n",
    "lyrics = {}\n",
    "\n",
    "# Define the artist names and file paths\n",
    "artists = {\n",
    "    'cher': '/Users/Luis Perez/Documents/lyrics/cher',\n",
    "    'robyn': '/Users/Luis Perez/Documents/lyrics/robyn'\n",
    "}\n",
    "\n",
    "for artist_name, artist_path in artists.items():\n",
    "    artist_lyrics = {}\n",
    "    # loop over files on artist folder\n",
    "    for file in os.listdir(artist_path):\n",
    "        #  if lyrics file ends with .txt\n",
    "        if file.endswith(\".txt\"):\n",
    "            song_name = file.split(\"_\")[-1].split(\".\")[0]\n",
    "            with open(os.path.join(artist_path, file), 'r') as f:\n",
    "                artist_lyrics[song_name] = f.read()\n",
    "    \n",
    "    lyrics[artist_name] = artist_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "e19287ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the twitter data\n",
    "\n",
    "artists = {\n",
    "    'cher': [],\n",
    "    'robyn': [],\n",
    "}\n",
    "for file in os.listdir(\"/Users/Luis Perez/Documents/twitter\"):\n",
    "    # first part of checking .txt file\n",
    "    if file.endswith(\"robynkonichiwa_follower_data.txt\"):\n",
    "        with open(os.path.join(\"/Users/Luis Perez/Documents/twitter\", file), 'r', encoding=\"utf-8\") as f:\n",
    "            csvFile = csv.DictReader(f, delimiter='\\t')\n",
    "            for row in csvFile:\n",
    "                if 'description' in row:\n",
    "                    artists['robyn'].append(row['description'])\n",
    "    # second part of checking .txt filer cher\n",
    "    elif file.endswith(\"cher_follower_data.txt\"):\n",
    "        with open(os.path.join(\"/Users/Luis Perez/Documents/twitter\", file), 'r', encoding=\"utf-8\") as f:\n",
    "            csvFile = csv.DictReader(f, delimiter='\\t')\n",
    "            for row in csvFile:\n",
    "                if 'description' in row:\n",
    "                    artists['cher'].append(row['description'])\n",
    "\n",
    "                            \n",
    "                    \n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "71c73d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "49808441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your clean twitter data here\n",
    "\n",
    "\n",
    "def twitter_clean_and_tokenize(text):\n",
    "    \n",
    "    #punctuation characters except #'s'\n",
    "    text_without_hash = string.punctuation.replace(\"#\", \"\")\n",
    "    trans_table = str.maketrans(\"\", \"\", text_without_hash)\n",
    "\n",
    "    #remove punctuation\n",
    "    text = text.translate(trans_table)\n",
    "    \n",
    "    #split on whitespace\n",
    "    tokens= text.split()\n",
    "    \n",
    "    \n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove stopwords \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    rm_stopwords= [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return rm_stopwords \n",
    "\n",
    "# Iterate over the artists and their descriptions\n",
    "for artist, descriptions in artists.items():\n",
    "    cleaned_descriptions = []\n",
    "    for description in descriptions:\n",
    "        if description:  # check if empty\n",
    "            cleaned_descriptions.append(twitter_clean_and_tokenize(description))\n",
    "    artists[artist] = cleaned_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "fb17a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to access the dictionary inner lists values\n",
    "cher_clyrics_tokens = []\n",
    "for artist, songs in cleaned_lyrics.items():\n",
    "     if artist == \"cher\":\n",
    "        for song,song_list in songs.items():\n",
    "            cher_clyrics_tokens += song_list\n",
    "            \n",
    "robyn_clyrics_tokens = []\n",
    "for artist, songs in cleaned_lyrics.items():\n",
    "     if artist == \"robyn\":\n",
    "        for song,song_list in songs.items():\n",
    "            robyn_clyrics_tokens += song_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "1fc8f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#was having trouble using list of list so decided to flatten lists\n",
    "cher_twitter_flat_tokens = [artists['cher'] for sublist in artists['cher'] for artists['cher'] in sublist]\n",
    "robyn_twitter_flat_tokens = [artists['robyn'] for sublist in artists['robyn'] for artists['robyn'] in sublist]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "e0f22e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your clean lyrics data here\n",
    "\n",
    "def lyrics_clean_and_tokenize(text):\n",
    "    \n",
    "    # Remove punctuation characters\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    #split on whitespace\n",
    "    tokens= text.split()\n",
    "    \n",
    "    \n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove stopwords \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    rm_stopwords= [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return rm_stopwords \n",
    "\n",
    "cleaned_lyrics= {}\n",
    "cleaned_lyrics2= {}\n",
    "\n",
    "for artist, artist_lyrics in lyrics.items():\n",
    "    cleaned_lyrics[artist] = {}\n",
    "    for song,song_lyrics in artist_lyrics.items():\n",
    "        if song_lyrics:  # check if lyrics is not empty\n",
    "            cleaned_lyrics[artist][song]= lyrics_clean_and_tokenize(song_lyrics)\n",
    "            cleaned_lyrics2[song]= lyrics_clean_and_tokenize(song_lyrics)\n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "f0bbedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter descriptions for: Cher\n",
      "There are 235394 tokens in the data.\n",
      "There are 73153 unique tokens in the data.\n",
      "There are 1372841 characters in the data.\n",
      "The lexical diversity is 0.311 in the data.\n",
      "\n",
      "Twitter descriptions for: Robyn\n",
      "There are 291103 tokens in the data.\n",
      "There are 88463 unique tokens in the data.\n",
      "There are 1750339 characters in the data.\n",
      "The lexical diversity is 0.304 in the data.\n",
      "\n",
      "lyrics descriptions for: Cher\n",
      "There are 44652 tokens in the data.\n",
      "There are 4647 unique tokens in the data.\n",
      "There are 193719 characters in the data.\n",
      "The lexical diversity is 0.104 in the data.\n",
      "\n",
      "lyrics descriptions for: Robyn\n",
      "There are 18229 tokens in the data.\n",
      "There are 2591 unique tokens in the data.\n",
      "There are 81176 characters in the data.\n",
      "The lexical diversity is 0.142 in the data.\n"
     ]
    }
   ],
   "source": [
    "# calls to descriptive_stats here\n",
    "\n",
    "#twitter section\n",
    "print(\"\\nTwitter descriptions for: Cher\")\n",
    "assert(descriptive_stats(cher_twitter_flat_tokens, verbose=True))\n",
    "print(\"\\nTwitter descriptions for: Robyn\")\n",
    "assert(descriptive_stats(robyn_twitter_flat_tokens, verbose=True))\n",
    "\n",
    "#lyrics section\n",
    "print(\"\\nlyrics descriptions for: Cher\")\n",
    "assert(descriptive_stats(cher_clyrics_tokens, verbose=True))\n",
    "print(\"\\nlyrics descriptions for: Robyn\")\n",
    "assert(descriptive_stats(robyn_clyrics_tokens, verbose=True))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: If we left stopwords in the data the top 5 might consists only stopwords like of: 'a','the','are','is', 'and'\n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: My prior beliefs about the lexical diversity was that their works would contain similar words in their lyrics. In other words, I was expecting that their lexical diversity would be in the lower numbers as artists do not tend to divert to much of their proven formulas---song writing, topics,etc--- according to a quick search a lexically dense text would be around 56%. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(emoji.is_emoji(\"❤️\"))\n",
    "assert(not emoji.is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis 😁\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "70af0572",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#emoji calc for robyn\n",
    "\n",
    "# list of twitter descriptions\n",
    "flat_tokens\n",
    "\n",
    "n = 10\n",
    "# create an empty dictionary to store the emojis and their frequencies\n",
    "emoji_freq = {}\n",
    "\n",
    "for description in flat_tokens:\n",
    "    #unicode for the emojis\n",
    "    desc = emoji.emojize(description)\n",
    "    for char in desc:\n",
    "        if emoji.is_emoji(char):\n",
    "            if char in emoji_freq:\n",
    "                emoji_freq[char] += 1\n",
    "            else:\n",
    "                emoji_freq[char] = 1\n",
    "\n",
    "# sort the dict by desc order\n",
    "sorted_emoji = dict(sorted(emoji_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "#top 10 most common emojis\n",
    "robyn_top_n_emoji = dict(list(sorted_emoji.items())[:n])\n",
    "\n",
    "#emoji calc for cher\n",
    "n = 10\n",
    "emoji_freq = {}\n",
    "\n",
    "for description in flat_tokens2:\n",
    "    desc = emoji.emojize(description)\n",
    "    for char in desc:\n",
    "        if emoji.is_emoji(char):\n",
    "            if char in emoji_freq:\n",
    "                emoji_freq[char] += 1\n",
    "            else:\n",
    "                emoji_freq[char] = 1\n",
    "\n",
    "# sort the dict by desc order\n",
    "sorted_emoji = dict(sorted(emoji_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "#top 10 most common emojis\n",
    "cher_top_n_emoji = dict(list(sorted_emoji.items())[:n])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "143a99dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cher's top 10 emojis used in their their followers' descriptions\n",
      "{'🌈': 2184, '🏳': 1748, '❤': 835, '✨': 767, '🏻': 501, '🏼': 359, '💙': 339, '💜': 338, '🎶': 268, '🏽': 265}\n",
      "\n",
      "Robyn's top 10 emojis used in their their followers' descriptions\n",
      "{'❤': 1176, '🌈': 950, '🏳': 810, '💙': 659, '✨': 587, '🏻': 448, '💜': 357, '🖤': 343, '🌊': 326, '🏼': 309}\n"
     ]
    }
   ],
   "source": [
    "# output the top n most common emojis\n",
    "print(\"Cher's top 10 emojis used in their their followers' descriptions\")\n",
    "print(cher_top_n_emoji)\n",
    "\n",
    "print(\"\\nRobyn's top 10 emojis used in their their followers' descriptions\")\n",
    "print(robyn_top_n_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9b770",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "07c396f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 #'s for Cher:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('#blm', 130),\n",
       " ('#resist', 82),\n",
       " ('#blacklivesmatter', 61),\n",
       " ('#1', 53),\n",
       " ('#voteblue', 50),\n",
       " ('#lgbtq', 26),\n",
       " ('#bluecrew', 26),\n",
       " ('#', 24),\n",
       " ('#fbr', 20),\n",
       " ('#prochoice', 19)]"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hastags for Cher\n",
    "hashtags = [s for s in cher_twitter_flat_tokens if s.startswith(\"#\")]\n",
    "hashtags = [s.lower() for s in hashtags]\n",
    "counts_hastags = Counter(hashtags)\n",
    "cher_top_10 = counts_hastags.most_common(10)\n",
    "\n",
    "\n",
    "print(\"Top 10 #'s for Cher:\")\n",
    "cher_top_10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "fbef1aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 #'s for Robyn:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('#blacklivesmatter', 212),\n",
       " ('#blm', 137),\n",
       " ('#1', 61),\n",
       " ('#music', 45),\n",
       " ('#resist', 32),\n",
       " ('#lgbtq', 27),\n",
       " ('#translivesmatter', 27),\n",
       " ('#freepalestine', 25),\n",
       " ('#blacktranslivesmatter', 20),\n",
       " ('#actuallyautistic', 19)]"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hastags for Robyn\n",
    "robyn_hashtags = [s for s in robyn_twitter_flat_tokens if s.startswith(\"#\")]\n",
    "robyn_hashtags = [s.lower() for s in robyn_hashtags]\n",
    "r_counts_hastags = Counter(robyn_hashtags)\n",
    "robyn_top_10 = r_counts_hastags.most_common(10)\n",
    "\n",
    "print(\"Top 10 #'s for Robyn:\")\n",
    "robyn_top_10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "f3847f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words in Cher's song titles are: \n",
      "[('The', 54), ('I', 45), ('You', 40), ('Love', 38), ('To', 28)]\n"
     ]
    }
   ],
   "source": [
    "#grabing all the songs titles from the lyrics dict \"song title (with spaces)\"\n",
    "new_list = {}\n",
    "for key, value in lyrics['cher'].items():\n",
    "    value_list = re.findall(r'\"([^\"]*)\"', value)\n",
    "    new_list[key] = value_list\n",
    "    \n",
    "#loop all the song titles to find top words\n",
    "all_words = []\n",
    "for key, value in new_list.items():\n",
    "    for song in value:\n",
    "        all_words += song.split()\n",
    "        \n",
    "common_words = Counter(all_words).most_common(5)\n",
    "print(\"Top 5 words in Cher's song titles are: \\n\" + str(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "729b68fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words in Robyn's song titles are: \n",
      "[('Me', 11), ('You', 8), ('The', 8), ('My', 8), ('be', 6)]\n"
     ]
    }
   ],
   "source": [
    "#grabing all the songs titles from the lyrics dict \"song title (with spaces)\"\n",
    "new_list = {}\n",
    "for key, value in lyrics['robyn'].items():\n",
    "    value_list = re.findall(r'\"([^\"]*)\"', value)\n",
    "    new_list[key] = value_list\n",
    "    \n",
    "#loop all the song titles to find top words\n",
    "all_words = []\n",
    "for key, value in new_list.items():\n",
    "    for song in value:\n",
    "        all_words += song.split()\n",
    "        \n",
    "common_words = Counter(all_words).most_common(5)\n",
    "print(\"Top 5 words in Robyn's song titles are: \\n\" + str(common_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "805a1e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Artist 1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Artist 2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 934,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "8acf816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total tokens by per song per artist \n",
    "artists_clyrics_tokens = []\n",
    "artists = [\"cher\", \"robyn\"]\n",
    "for artist, songs in cleaned_lyrics.items():\n",
    "    if artist in artists:\n",
    "        for song,song_list in songs.items():\n",
    "            song_info = {'artist':artist, 'length':len(song_list)}\n",
    "            artists_clyrics_tokens.append(song_info)\n",
    "df = pd.DataFrame(artists_clyrics_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "da3b002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "cher     AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "robyn    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: This will match on white space (spaces between words, tabs) and the + sign indicates that eithe one or more should be matched. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
